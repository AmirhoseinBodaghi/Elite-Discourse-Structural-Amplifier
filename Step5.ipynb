{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c5fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 1 — Imports & User Config\n",
    "# ==============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===== PATHS =====\n",
    "STEP4_DIR = Path(r\" \")\n",
    "STEP5_DIR = Path(r\" \")\n",
    "STEP5_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ===== CATEGORY DICT (Option 1: Each person → Exactly one category) =====\n",
    "CATEGORY_DICT = {\n",
    "    # Politicians & world leaders\n",
    "    \"Politicians and World Leaders\": [\n",
    "        \"Abdelfattah Elsisi\",\"Alberto Fernández\",\"Barack Obama\",\"Benjamin Netanyahu\",\"Boris Johnson\",\n",
    "        \"Emmanuel Macron\",\"Imran Khan\",\"Ivan Duque\",\"Jair Bolsonaro\",\"Joko Widodo\",\"Justin Trudeau\",\n",
    "        \"Kaguta Museveni\",\"King Salman\",\"Lopez Obrador\",\"Mohammed AlMaktoum\",\"Moon Jaein\",\n",
    "        \"Muhammadu Buhari\",\"Nana AkufoAddo\",\"Narendra Modi\",\"Nicolas Maduro\",\"Paul Kagame\",\"Queen Rania\",\"Sebastian Pinera\",\"Tayyip Erdogan\"\n",
    "    ],\n",
    "\n",
    "    # Business / entrepreneurs\n",
    "    \"Business Leaders and Entrepreneurs\": [\n",
    "        \"Bill Gates\",\"Elon Musk\",\"Eric Yuan\",\"Jack Dorsey\",\"Joe Gebbia\",\"John Collison\",\"Ken Fisher\",\n",
    "        \"Marc Benioff\",\"Melinda Gates\",\"Michael Dell\",\"Micky Arison\",\"Mike Bloomberg\",\"Mike Brookes\",\n",
    "        \"Orlando Bravo\",\"Patrick Collison\",\"Ralph Lauren\",\"Ricardo Salinas\",\"Samuel Bankman\",\n",
    "        \"Tilman Fertitta\",\"Tim Sweeney\",\"Tobi Lutke\",\"Vinod Khosla\"\n",
    "    ],\n",
    "\n",
    "    # Entertainment umbrella: actors, athletes, comedians, models\n",
    "    \"Entertainers and Celebrities\": [\n",
    "        # singers, actors, athletes, comedians, reality stars\n",
    "        \"Adele Adkins\",\"Alecia Beth\",\"Alicia Keys\",\"Armando Perez\",\"Britney Spears\",\"Bruno Mars\",\n",
    "        \"Chris Brown\",\"Demi Lovato\",\"Drake Graham\",\"Harry Styles\",\"Jennifer Lopez\",\"Justin Bieber\",\n",
    "        \"Justin Timberlake\",\"Kanye West\",\"Katy Perry\",\"Lady Gaga\",\"Liam Payne\",\"Lil Wayne\",\n",
    "        \"Louis Tomlinson\",\"Miley Cyrus\",\"Niall Horan\",\"Nicki Minaj\",\"Robyn Rihanna\",\"Shakira Ripoll\",\n",
    "        \"Shawn Mendes\",\"Taylor Swift\",\"Wiz Khalifa\",\"Zayn Malik\",\n",
    "        \"Akshay Kumar\",\"Amitabh Bachchan\",\"Deepika Padukone\",\"Emma Watson\",\"Hrithik Roshan\",\n",
    "        \"Priyanka Chopra\",\"Salman Khan\",\"Selena Gomez\",\"ShahRukh Khan\",\n",
    "        \"Andres Iniesta\",\"Cristiano Ronaldo\",\"LeBron James\",\"Mesut Ozil\",\"Neymar Junior\",\n",
    "        \"Ricardo Kaka\",\"Sachin Tendulkar\",\"Virat Kohli\",\n",
    "        \"Conan O Brien\",\"Jimmy Fallon\",\"Kevin Hart\",\"Oprah Winfrey\",\"Patrick Harris\",\"Whindersson Nunes\",\n",
    "        \"Kendal Jenner\",\"Khloe Kardashian\",\"Kim Kardashian\",\"Kourtney Kardashian\",\"Kylie Jenner\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "FOLLOWERS_DICT = {\n",
    "    \"Abdelfattah Elsisi\": 6300000,\n",
    "    \"Alberto Fernández\": 2200000,\n",
    "    \"Barack Obama\": 129000000,\n",
    "    \"Benjamin Netanyahu\": 3500000,\n",
    "    \"Boris Johnson\": 4500000,\n",
    "    \"Emmanuel Macron\": 10200000,\n",
    "    \"Imran Khan\": 21200000,\n",
    "    \"Ivan Duque\": 2600000,\n",
    "    \"Jair Bolsonaro\": 14100000,\n",
    "    \"Joko Widodo\": 21700000,\n",
    "    \"Justin Trudeau\": 6600000,\n",
    "    \"Kaguta Museveni\": 3600000,\n",
    "    \"King Salman\": 10200000,\n",
    "    \"Lopez Obrador\": 11000000,\n",
    "    \"Mohammed AlMaktoum\": 10900000,\n",
    "    \"Moon Jaein\": 2100000,\n",
    "    \"Muhammadu Buhari\": 4500000,\n",
    "    \"Nana AkufoAddo\": 2700000,\n",
    "    \"Narendra Modi\": 108600000,\n",
    "    \"Nicolas Maduro\": 4700000,\n",
    "    \"Paul Kagame\": 3300000,\n",
    "    \"Queen Rania\": 9700000,\n",
    "    \"Sebastian Pinera\": 2300000,\n",
    "    \"Tayyip Erdogan\": 21300000,\n",
    "    \"Adele Adkins\": 25500000,\n",
    "    \"Alecia Beth\": 28700000,\n",
    "    \"Alicia Keys\": 27700000,\n",
    "    \"Armando Perez\": 22800000,\n",
    "    \"Britney Spears\": 51600000,\n",
    "    \"Bruno Mars\": 40900000,\n",
    "    \"Chris Brown\": 30500000,\n",
    "    \"Demi Lovato\": 50000000,\n",
    "    \"Drake Graham\": 37800000,\n",
    "    \"Harry Styles\": 35300000,\n",
    "    \"Jennifer Lopez\": 42200000,\n",
    "    \"Justin Bieber\": 105700000,\n",
    "    \"Justin Timberlake\": 57400000,\n",
    "    \"Kanye West\": 32700000,\n",
    "    \"Katy Perry\": 101300000,\n",
    "    \"Lady Gaga\": 79700000,\n",
    "    \"Liam Payne\": 31600000,\n",
    "    \"Lil Wayne\": 32900000,\n",
    "    \"Louis Tomlinson\": 33500000,\n",
    "    \"Miley Cyrus\": 44600000,\n",
    "    \"Niall Horan\": 38200000,\n",
    "    \"Nicki Minaj\": 27800000,\n",
    "    \"Robyn Rihanna\": 105800000,\n",
    "    \"Shakira Ripoll\": 51300000,\n",
    "    \"Shawn Mendes\": 25200000,\n",
    "    \"Taylor Swift\": 91400000,\n",
    "    \"Wiz Khalifa\": 34700000,\n",
    "    \"Zayn Malik\": 29200000,\n",
    "    \"Akshay Kumar\": 46600000,\n",
    "    \"Amitabh Bachchan\": 48300000,\n",
    "    \"Deepika Padukone\": 25700000,\n",
    "    \"Emma Watson\": 25700000,\n",
    "    \"Hrithik Roshan\": 31800000,\n",
    "    \"Priyanka Chopra\": 26800000,\n",
    "    \"Salman Khan\": 45200000,\n",
    "    \"Selena Gomez\": 63600000,\n",
    "    \"ShahRukh Khan\": 43500000,\n",
    "    \"Andres Iniesta\": 24300000,\n",
    "    \"Cristiano Ronaldo\": 114200000,\n",
    "    \"LeBron James\": 52000000,\n",
    "    \"Mesut Ozil\": 25300000,\n",
    "    \"Neymar Junior\": 62900000,\n",
    "    \"Ricardo Kaka\": 27400000,\n",
    "    \"Sachin Tendulkar\": 40500000,\n",
    "    \"Virat Kohli\": 67500000,\n",
    "    \"Conan O Brien\": 26100000,\n",
    "    \"Jimmy Fallon\": 47800000,\n",
    "    \"Kevin Hart\": 35200000,\n",
    "    \"Oprah Winfrey\": 39400000,\n",
    "    \"Patrick Harris\": 23100000,\n",
    "    \"Whindersson Nunes\": 27600000,\n",
    "    \"Kendal Jenner\": 30600000,\n",
    "    \"Khloe Kardashian\": 29200000,\n",
    "    \"Kim Kardashian\": 73300000,\n",
    "    \"Kourtney Kardashian\": 25200000,\n",
    "    \"Kylie Jenner\": 38900000,\n",
    "    \"Bill Gates\": 66000000,\n",
    "    \"Elon Musk\": 228500000,\n",
    "    \"Eric Yuan\": 86800,\n",
    "    \"Jack Dorsey\": 6400000,\n",
    "    \"Joe Gebbia\": 206100,\n",
    "    \"John Collison\": 208500,\n",
    "    \"Ken Fisher\": 428300,\n",
    "    \"Marc Benioff\": 1100000,\n",
    "    \"Melinda Gates\": 2400000,\n",
    "    \"Michael Dell\": 796100,\n",
    "    \"Micky Arison\": 184800,\n",
    "    \"Mike Bloomberg\": 2500000,\n",
    "    \"Mike Brookes\": 105100,\n",
    "    \"Orlando Bravo\": 44100,\n",
    "    \"Patrick Collison\": 572000,\n",
    "    \"Ralph Lauren\": 2200000,\n",
    "    \"Ricardo Salinas\": 2100000,\n",
    "    \"Samuel Bankman\": 996800,\n",
    "    \"Tilman Fertitta\": 103800,\n",
    "    \"Tim Sweeney\": 316100,\n",
    "    \"Tobi Lutke\": 424100,\n",
    "    \"Vinod Khosla\": 686500\n",
    "\n",
    "    # ... include all others or read from a CSV later\n",
    "}\n",
    "\n",
    "AGE_DICT = {\n",
    "    \"Abdelfattah Elsisi\": 66,\n",
    "    \"Alberto Fernández\": 62,\n",
    "    \"Barack Obama\": 60,\n",
    "    \"Benjamin Netanyahu\": 72,\n",
    "    \"Boris Johnson\": 57,\n",
    "    \"Emmanuel Macron\": 43,\n",
    "    \"Imran Khan\": 69,\n",
    "    \"Ivan Duque\": 45,\n",
    "    \"Jair Bolsonaro\": 66,\n",
    "    \"Joko Widodo\": 60,\n",
    "    \"Justin Trudeau\": 49,\n",
    "    \"Kaguta Museveni\": 77,\n",
    "    \"King Salman\": 85,\n",
    "    \"Lopez Obrador\": 68,\n",
    "    \"Mohammed AlMaktoum\": 72,\n",
    "    \"Moon Jaein\": 68,\n",
    "    \"Muhammadu Buhari\": 79,\n",
    "    \"Nana AkufoAddo\": 77,\n",
    "    \"Narendra Modi\": 71,\n",
    "    \"Nicolas Maduro\": 58,\n",
    "    \"Paul Kagame\": 64,\n",
    "    \"Queen Rania\": 51,\n",
    "    \"Sebastian Pinera\": 71,\n",
    "    \"Tayyip Erdogan\": 67,\n",
    "    \"Adele Adkins\": 33,\n",
    "    \"Alecia Beth\": 42,\n",
    "    \"Alicia Keys\": 40,\n",
    "    \"Armando Perez\": 40,\n",
    "    \"Britney Spears\": 39,\n",
    "    \"Bruno Mars\": 36,\n",
    "    \"Chris Brown\": 32,\n",
    "    \"Demi Lovato\": 29,\n",
    "    \"Drake Graham\": 35,\n",
    "    \"Harry Styles\": 27,\n",
    "    \"Jennifer Lopez\": 52,\n",
    "    \"Justin Bieber\": 27,\n",
    "    \"Justin Timberlake\": 40,\n",
    "    \"Kanye West\": 44,\n",
    "    \"Katy Perry\": 37,\n",
    "    \"Lady Gaga\": 35,\n",
    "    \"Liam Payne\": 28,\n",
    "    \"Lil Wayne\": 39,\n",
    "    \"Louis Tomlinson\": 29,\n",
    "    \"Miley Cyrus\": 28,\n",
    "    \"Niall Horan\": 28,\n",
    "    \"Nicki Minaj\": 38,\n",
    "    \"Robyn Rihanna\": 33,\n",
    "    \"Shakira Ripoll\": 44,\n",
    "    \"Shawn Mendes\": 23,\n",
    "    \"Taylor Swift\": 31,\n",
    "    \"Wiz Khalifa\": 34,\n",
    "    \"Zayn Malik\": 28,\n",
    "    \"Akshay Kumar\": 54,\n",
    "    \"Amitabh Bachchan\": 79,\n",
    "    \"Deepika Padukone\": 35,\n",
    "    \"Emma Watson\": 31,\n",
    "    \"Hrithik Roshan\": 47,\n",
    "    \"Priyanka Chopra\": 39,\n",
    "    \"Salman Khan\": 55,\n",
    "    \"Selena Gomez\": 29,\n",
    "    \"ShahRukh Khan\": 56,\n",
    "    \"Andres Iniesta\": 37,\n",
    "    \"Cristiano Ronaldo\": 36,\n",
    "    \"LeBron James\": 36,\n",
    "    \"Mesut Ozil\": 34,\n",
    "    \"Neymar Junior\": 29,\n",
    "    \"Ricardo Kaka\": 39,\n",
    "    \"Sachin Tendulkar\": 48,\n",
    "    \"Virat Kohli\": 33,\n",
    "    \"Conan O Brien\": 58,\n",
    "    \"Jimmy Fallon\": 47,\n",
    "    \"Kevin Hart\": 42,\n",
    "    \"Oprah Winfrey\": 67,\n",
    "    \"Patrick Harris\": 48,\n",
    "    \"Whindersson Nunes\": 26,\n",
    "    \"Kendal Jenner\": 26,\n",
    "    \"Khloe Kardashian\": 37,\n",
    "    \"Kim Kardashian\": 41,\n",
    "    \"Kourtney Kardashian\": 42,\n",
    "    \"Kylie Jenner\": 24,\n",
    "    \"Bill Gates\": 66,\n",
    "    \"Elon Musk\": 50,\n",
    "    \"Eric Yuan\": 51,\n",
    "    \"Jack Dorsey\": 44,\n",
    "    \"Joe Gebbia\": 40,\n",
    "    \"John Collison\": 31,\n",
    "    \"Ken Fisher\": 70,\n",
    "    \"Marc Benioff\": 57,\n",
    "    \"Melinda Gates\": 57,\n",
    "    \"Michael Dell\": 56,\n",
    "    \"Micky Arison\": 72,\n",
    "    \"Mike Bloomberg\": 79,\n",
    "    \"Mike Brookes\": 41,\n",
    "    \"Orlando Bravo\": 51,\n",
    "    \"Patrick Collison\": 33,\n",
    "    \"Ralph Lauren\": 82,\n",
    "    \"Ricardo Salinas\": 66,\n",
    "    \"Samuel Bankman\": 29,\n",
    "    \"Tilman Fertitta\": 64,\n",
    "    \"Tim Sweeney\": 51,\n",
    "    \"Tobi Lutke\": 41,\n",
    "    \"Vinod Khosla\": 66\n",
    "\n",
    "    # ... include all others or read from a CSV later\n",
    "}\n",
    "\n",
    "JOIN_DICT = {\n",
    "    \"Abdelfattah Elsisi\": 2014,\n",
    "    \"Alberto Fernández\": 2010,\n",
    "    \"Barack Obama\": 2007,\n",
    "    \"Benjamin Netanyahu\": 2008,\n",
    "    \"Boris Johnson\": 2015,\n",
    "    \"Emmanuel Macron\": 2013,\n",
    "    \"Imran Khan\": 2010,\n",
    "    \"Ivan Duque\": 2009,\n",
    "    \"Jair Bolsonaro\": 2010,\n",
    "    \"Joko Widodo\": 2011,\n",
    "    \"Justin Trudeau\": 2008,\n",
    "    \"Kaguta Museveni\": 2010,\n",
    "    \"King Salman\": 2013,\n",
    "    \"Lopez Obrador\": 2009,\n",
    "    \"Mohammed AlMaktoum\": 2009,\n",
    "    \"Moon Jaein\": 2011,\n",
    "    \"Muhammadu Buhari\": 2014,\n",
    "    \"Nana AkufoAddo\": 2011,\n",
    "    \"Narendra Modi\": 2009,\n",
    "    \"Nicolas Maduro\": 2013,\n",
    "    \"Paul Kagame\": 2009,\n",
    "    \"Queen Rania\": 2009,\n",
    "    \"Sebastian Pinera\": 2008,\n",
    "    \"Tayyip Erdogan\": 2009,\n",
    "    \"Adele Adkins\": 2010,\n",
    "    \"Alecia Beth\": 2009,\n",
    "    \"Alicia Keys\": 2009,\n",
    "    \"Armando Perez\": 2009,\n",
    "    \"Britney Spears\": 2008,\n",
    "    \"Bruno Mars\": 2009,\n",
    "    \"Chris Brown\": 2010,\n",
    "    \"Demi Lovato\": 2009,\n",
    "    \"Drake Graham\": 2009,\n",
    "    \"Harry Styles\": 2010,\n",
    "    \"Jennifer Lopez\": 2009,\n",
    "    \"Justin Bieber\": 2009,\n",
    "    \"Justin Timberlake\": 2009,\n",
    "    \"Kanye West\": 2010,\n",
    "    \"Katy Perry\": 2009,\n",
    "    \"Lady Gaga\": 2008,\n",
    "    \"Liam Payne\": 2010,\n",
    "    \"Lil Wayne\": 2010,\n",
    "    \"Louis Tomlinson\": 2009,\n",
    "    \"Miley Cyrus\": 2011,\n",
    "    \"Niall Horan\": 2010,\n",
    "    \"Nicki Minaj\": 2009,\n",
    "    \"Robyn Rihanna\": 2009,\n",
    "    \"Shakira Ripoll\": 2009,\n",
    "    \"Shawn Mendes\": 2011,\n",
    "    \"Taylor Swift\": 2008,\n",
    "    \"Wiz Khalifa\": 2009,\n",
    "    \"Zayn Malik\": 2010,\n",
    "    \"Akshay Kumar\": 2009,\n",
    "    \"Amitabh Bachchan\": 2010,\n",
    "    \"Deepika Padukone\": 2010,\n",
    "    \"Emma Watson\": 2010,\n",
    "    \"Hrithik Roshan\": 2010,\n",
    "    \"Priyanka Chopra\": 2009,\n",
    "    \"Salman Khan\": 2010,\n",
    "    \"Selena Gomez\": 2009,\n",
    "    \"ShahRukh Khan\": 2010,\n",
    "    \"Andres Iniesta\": 2009,\n",
    "    \"Cristiano Ronaldo\": 2010,\n",
    "    \"LeBron James\": 2009,\n",
    "    \"Mesut Ozil\": 2012,\n",
    "    \"Neymar Junior\": 2010,\n",
    "    \"Ricardo Kaka\": 2009,\n",
    "    \"Sachin Tendulkar\": 2010,\n",
    "    \"Virat Kohli\": 2009,\n",
    "    \"Conan O Brien\": 2010,\n",
    "    \"Jimmy Fallon\": 2008,\n",
    "    \"Kevin Hart\": 2009,\n",
    "    \"Oprah Winfrey\": 2009,\n",
    "    \"Patrick Harris\": 2009,\n",
    "    \"Whindersson Nunes\": 2010,\n",
    "    \"Kendal Jenner\": 2010,\n",
    "    \"Khloe Kardashian\": 2009,\n",
    "    \"Kim Kardashian\": 2009,\n",
    "    \"Kourtney Kardashian\": 2009,\n",
    "    \"Kylie Jenner\": 2011,\n",
    "    \"Bill Gates\": 2009,\n",
    "    \"Elon Musk\": 2009,\n",
    "    \"Eric Yuan\": 2012,\n",
    "    \"Jack Dorsey\": 2006,\n",
    "    \"Joe Gebbia\": 2007,\n",
    "    \"John Collison\": 2007,\n",
    "    \"Ken Fisher\": 2017,\n",
    "    \"Marc Benioff\": 2009,\n",
    "    \"Melinda Gates\": 2010,\n",
    "    \"Michael Dell\": 2009,\n",
    "    \"Micky Arison\": 2011,\n",
    "    \"Mike Bloomberg\": 2008,\n",
    "    \"Mike Brookes\": 2008,\n",
    "    \"Orlando Bravo\": 2013,\n",
    "    \"Patrick Collison\": 2007,\n",
    "    \"Ralph Lauren\": 2009,\n",
    "    \"Ricardo Salinas\": 2009,\n",
    "    \"Samuel Bankman\": 2019,\n",
    "    \"Tilman Fertitta\": 2013,\n",
    "    \"Tim Sweeney\": 2013,\n",
    "    \"Tobi Lutke\": 2007,\n",
    "    \"Vinod Khosla\": 2009\n",
    "\n",
    "    # ... include all others or read from a CSV later\n",
    "}\n",
    "\n",
    "YEARS_ACTIVE_DICT = {p: 2021 - year for p, year in JOIN_DICT.items()}\n",
    "\n",
    "def normalize_person_key(name: str) -> str:\n",
    "    if not isinstance(name, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # ============ HARD FIXES FOR THE TWO PROBLEMATIC NAMES ============\n",
    "    hard_fixes = {\n",
    "        \"ConanOBrien\":       \"Conan O'Brien\",     # correct with apostrophe\n",
    "        \"AbdelfattahElsisi\": \"Abdelfattah Elsisi\", # ← FIXED: capital E and S !!\n",
    "    }\n",
    "    if name in hard_fixes:\n",
    "        return hard_fixes[name]\n",
    "    \n",
    "    # ============ STANDARD CAMELCASE → SPACE FOR EVERYONE ELSE ============\n",
    "    name = re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', name)   # insert space before capitals\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()           # collapse spaces\n",
    "    \n",
    "    # ============ EXTRA SAFETY (in case regex ever breaks again) ============\n",
    "    if name == \"Conan O Brien\":\n",
    "        return \"Conan O'Brien\"\n",
    "    if name == \"Abdelfattah El sisi\":\n",
    "        return \"Abdelfattah Elsisi\"\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "# Build person → category mapping (Option 1)\n",
    "category_norm = {}\n",
    "for cat, people in CATEGORY_DICT.items():\n",
    "    for p in people:\n",
    "        category_norm[normalize_person_key(p)] = cat\n",
    "\n",
    "print(\"BLOCK 1 loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27625069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 2 — Build combined_long\n",
    "# ==============================\n",
    "\n",
    "def read_elite_summary(file_path: Path, person_name: str):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    metric_col = df.columns[0]\n",
    "    df = df.rename(columns={metric_col: \"metric\"})\n",
    "\n",
    "    for col in [\"Full\", \"COVID\", \"COVID/Full\", \"p_two_sided\", \"obs_value\",\n",
    "                \"null_mean\", \"null_std\", \"n_perm\", \"ratio_to_null_mean\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    df[\"person\"] = person_name\n",
    "    return df\n",
    "\n",
    "rows = []\n",
    "files_found = 0\n",
    "\n",
    "for person_dir in STEP4_DIR.iterdir():\n",
    "    if not person_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    person_name = person_dir.name\n",
    "    candidate = None\n",
    "\n",
    "    for f in person_dir.iterdir():\n",
    "        if f.is_file() and person_name in f.name and \"Centrality\" in f.name:\n",
    "            candidate = f\n",
    "            break\n",
    "\n",
    "    if candidate is None:\n",
    "        xs = list(person_dir.glob(\"*.xlsx\"))\n",
    "        if xs:\n",
    "            candidate = xs[0]\n",
    "\n",
    "    if candidate is None:\n",
    "        print(f\"⚠️ No file found in {person_dir}\")\n",
    "        continue\n",
    "\n",
    "    df_e = read_elite_summary(candidate, person_name)\n",
    "    if df_e is not None:\n",
    "        rows.append(df_e)\n",
    "        files_found += 1\n",
    "\n",
    "combined_long = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# normalize column names\n",
    "rename_map = {}\n",
    "for c in combined_long.columns:\n",
    "    lc = c.lower()\n",
    "    if lc == \"full\": rename_map[c] = \"full\"\n",
    "    if lc == \"covid\": rename_map[c] = \"covid\"\n",
    "    if lc in [\"covid/full\", \"covid_full_ratio\"]: rename_map[c] = \"covid_full_ratio\"\n",
    "    if lc == \"p_two_sided\": rename_map[c] = \"p_two_sided\"\n",
    "\n",
    "combined_long = combined_long.rename(columns=rename_map)\n",
    "combined_long[\"metric\"] = combined_long[\"metric\"].str.strip().str.lower()\n",
    "\n",
    "combined_long.to_csv(STEP5_DIR/\"combined_person_metric_long.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"combined_long saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ef733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# BLOCK 3 — Merge full metrics + COVID + metadata\n",
    "# ========================================\n",
    "\n",
    "# 1. Full-period metrics in wide format\n",
    "full_wide = (\n",
    "    combined_long[[\"person\", \"metric\", \"full\"]]\n",
    "    .dropna(subset=[\"full\"])\n",
    "    .pivot_table(index=\"person\", columns=\"metric\", values=\"full\", aggfunc=\"first\")\n",
    ")\n",
    "full_wide.columns = [f\"full_{c}\" for c in full_wide.columns]\n",
    "full_wide = full_wide.reset_index()\n",
    "\n",
    "# 2. COVID-period rows (only rows that actually have a COVID value)\n",
    "covid_rows = combined_long[\n",
    "    combined_long[\"covid\"].notna()\n",
    "].copy()\n",
    "\n",
    "covid_rows = covid_rows[[\n",
    "    \"person\", \"metric\", \"full\", \"covid\", \"covid_full_ratio\",\n",
    "    \"p_two_sided\", \"obs_value\", \"null_mean\", \"null_std\"\n",
    "]]\n",
    "\n",
    "# 3. Merge COVID rows with full-period metrics\n",
    "merged = covid_rows.merge(full_wide, on=\"person\", how=\"left\")\n",
    "\n",
    "# 4. Normalise person names ONCE\n",
    "merged[\"person_norm\"] = merged[\"person\"].apply(normalize_person_key)\n",
    "\n",
    "# 5. Normalised metadata dictionaries\n",
    "followers_norm = {normalize_person_key(k): v for k, v in FOLLOWERS_DICT.items()}\n",
    "age_norm       = {normalize_person_key(k): v for k, v in AGE_DICT.items()}\n",
    "years_norm     = {normalize_person_key(k): v for k, v in YEARS_ACTIVE_DICT.items()}\n",
    "\n",
    "# 6. Build metadata frame (only for people that appear in the data)\n",
    "meta = pd.DataFrame({\"person_norm\": merged[\"person_norm\"].unique()})\n",
    "meta[\"followers\"]     = meta[\"person_norm\"].map(followers_norm)\n",
    "meta[\"age\"]           = meta[\"person_norm\"].map(age_norm)\n",
    "meta[\"years_active\"]  = meta[\"person_norm\"].map(years_norm)\n",
    "meta[\"category\"]      = meta[\"person_norm\"].map(category_norm)\n",
    "\n",
    "# 7. Merge metadata in\n",
    "merged = merged.merge(meta, on=\"person_norm\", how=\"left\")\n",
    "\n",
    "# 8. Save\n",
    "merged.to_csv(\n",
    "    STEP5_DIR / \"merged_person_metric_covidsummary.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "print(f\"Block 3 complete → {len(merged):,} rows in merged table\")\n",
    "print(f\"   Unique elites: {merged['person'].nunique()}\")\n",
    "print(f\"   Categories present: {merged['category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c710cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 4 — Coverage summary\n",
    "# ==============================\n",
    "\n",
    "metrics = sorted(merged[\"metric\"].unique())\n",
    "summary_rows = []\n",
    "\n",
    "for m in metrics:\n",
    "    sub = merged[merged[\"metric\"]==m]\n",
    "    n = sub.shape[0]\n",
    "    sig = sub[\"p_two_sided\"].lt(0.05).sum()\n",
    "    marginal = sub[\"p_two_sided\"].lt(0.10).sum()\n",
    "    mean_ratio = sub[\"covid_full_ratio\"].replace([np.inf,-np.inf], np.nan).mean()\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"metric\": m,\n",
    "        \"n_elites_with_covid_ego\": n,\n",
    "        \"n_significant_p<0.05\": sig,\n",
    "        \"n_marginal_p<0.1\": marginal,\n",
    "        \"mean_ratio\": mean_ratio\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(STEP5_DIR/\"metric_coverage_summary.csv\", index=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e13b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 5 — OLS regressions\n",
    "# ==============================\n",
    "REG_DIR = STEP5_DIR / \"regression_results\"\n",
    "REG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "reg_results = []\n",
    "\n",
    "MIN_SIG = 10  # minimum significant elites\n",
    "\n",
    "for m in metrics:\n",
    "    sub = merged[merged[\"metric\"]==m].copy()\n",
    "    sub = sub[sub[\"covid_full_ratio\"].notna()]\n",
    "\n",
    "    sig = sub[sub[\"p_two_sided\"] < 0.05]\n",
    "    if len(sig) < MIN_SIG:\n",
    "        reg_results.append({\n",
    "            \"metric\": m, \"run\": False,\n",
    "            \"reason\": \"Too few significant elites\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    df = sig.copy()\n",
    "    df[\"log_followers\"] = np.log1p(df[\"followers\"].astype(float))\n",
    "\n",
    "    full_cols = [c for c in df.columns if c.startswith(\"full_\")]\n",
    "    core_full = [\"full_density\",\"full_clustering\",\"full_modularity\",\n",
    "                 \"full_centralization_top3\",\"full_n_nodes\",\"full_n_edges\",\n",
    "                 \"full_avg_degree\",\"full_avg_closeness\",\"full_avg_pagerank\"]\n",
    "    used_full = [c for c in core_full if c in df.columns]\n",
    "\n",
    "    rhs = [\"log_followers\",\"age\",\"years_active\",\"C(category)\"] + used_full\n",
    "    rhs = [c for c in rhs if c in df.columns]\n",
    "\n",
    "    formula = \"covid_full_ratio ~ \" + \" + \".join(rhs)\n",
    "    df2 = df[[\"covid_full_ratio\"]+rhs].dropna()\n",
    "    if df2.shape[0] < len(rhs)+3:\n",
    "        reg_results.append({\n",
    "            \"metric\": m, \"run\": False, \"reason\": \"Insufficient rows after NA drop\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    model = smf.ols(formula, df2).fit(cov_type=\"HC3\")\n",
    "\n",
    "    with open(REG_DIR/f\"{m}_reg_summary.txt\",\"w\") as f:\n",
    "        f.write(model.summary().as_text())\n",
    "\n",
    "    reg_results.append({\n",
    "        \"metric\": m, \"run\": True,\n",
    "        \"r2_adj\": model.rsquared_adj,\n",
    "        \"n_used\": df2.shape[0],\n",
    "        \"formula\": formula\n",
    "    })\n",
    "\n",
    "pd.DataFrame(reg_results).to_csv(STEP5_DIR/\"regression_overview.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa33ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 5 — OLS regressions (WITH TEXT FILES SAVED)\n",
    "# ==============================\n",
    "REG_DIR = STEP5_DIR / \"regression_results\"\n",
    "REG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "reg_results = []\n",
    "MIN_SIG = 10  # minimum significant elites\n",
    "\n",
    "for m in metrics:\n",
    "    sub = merged[merged[\"metric\"] == m].copy()\n",
    "    sub = sub[sub[\"covid_full_ratio\"].notna()]\n",
    "    sig = sub[sub[\"p_two_sided\"] < 0.05]\n",
    "    \n",
    "    if len(sig) < MIN_SIG:\n",
    "        reg_results.append({\"metric\": m, \"run\": False, \"reason\": \"Too few significant elites\"})\n",
    "        continue\n",
    "\n",
    "    df = sig.copy()\n",
    "    df[\"log_followers\"] = np.log1p(df[\"followers\"].astype(float))\n",
    "\n",
    "    full_cols = [c for c in df.columns if c.startswith(\"full_\")]\n",
    "    core_full = [\"full_density\",\"full_clustering\",\"full_modularity\",\n",
    "                 \"full_centralization_top3\",\"full_n_nodes\",\"full_n_edges\",\n",
    "                 \"full_avg_degree\",\"full_avg_closeness\",\"full_avg_pagerank\"]\n",
    "    used_full = [c for c in core_full if c in df.columns]\n",
    "    rhs = [\"log_followers\",\"age\",\"years_active\",\"C(category)\"] + used_full\n",
    "    rhs = [c for c in rhs if c in df.columns]\n",
    "    formula = \"covid_full_ratio ~ \" + \" + \".join(rhs)\n",
    "\n",
    "    df2 = df[[\"covid_full_ratio\"] + rhs].dropna()\n",
    "    if df2.shape[0] < len(rhs) + 3:\n",
    "        reg_results.append({\"metric\": m, \"run\": False, \"reason\": \"Insufficient rows after NA drop\"})\n",
    "        continue\n",
    "\n",
    "    model = smf.ols(formula, df2).fit(cov_type=\"HC3\")\n",
    "\n",
    "    # SAVE THE FULL REGRESSION SUMMARY TEXT FILE (this was missing!)\n",
    "    txt_path = REG_DIR / f\"{m}_reg_summary.txt\"\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(model.summary().as_text())\n",
    "\n",
    "    # Also save a nice HTML version (optional but pretty)\n",
    "    html_path = REG_DIR / f\"{m}_reg_summary.html\"\n",
    "    with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(model.summary().as_html())\n",
    "\n",
    "    reg_results.append({\n",
    "        \"metric\": m,\n",
    "        \"run\": True,\n",
    "        \"r2_adj\": model.rsquared_adj,\n",
    "        \"n_used\": df2.shape[0],\n",
    "        \"formula\": formula,\n",
    "        \"p_values\": {param: model.pvalues[param] for param in model.params.index}\n",
    "    })\n",
    "\n",
    "pd.DataFrame(reg_results).to_csv(STEP5_DIR / \"regression_overview.csv\", index=False)\n",
    "print(f\"Block 5 finished! → {len([r for r in reg_results if r['run']])} regressions saved in:\\n   {REG_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2857693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 6 — Category-level analysis (robust version)\n",
    "# ==============================\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import os\n",
    "\n",
    "cat_results = []\n",
    "tukey_dir = STEP5_DIR / \"Tukey_posthoc\"\n",
    "tukey_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Starting category-level analysis...\")\n",
    "\n",
    "for m in metrics:\n",
    "    # 1. Select data for this metric\n",
    "    sub = merged[\n",
    "        (merged[\"metric\"] == m) & \n",
    "        (merged[\"covid_full_ratio\"].notna())\n",
    "    ].copy()\n",
    "\n",
    "    # 2. CRITICAL: Drop rows where category is missing\n",
    "    if sub[\"category\"].isna().any():\n",
    "        n_dropped = sub[\"category\"].isna().sum()\n",
    "        print(f\"   → {m}: Dropping {n_dropped} rows with missing category\")\n",
    "        sub = sub.dropna(subset=[\"category\"])\n",
    "\n",
    "    # Need at least 2 categories AND at least 2 observations per category\n",
    "    if sub[\"category\"].nunique() < 2:\n",
    "        continue\n",
    "\n",
    "    # Quick check: each category should have ≥2 observations (Tukey requires this)\n",
    "    counts = sub[\"category\"].value_counts()\n",
    "    if (counts < 2).any():\n",
    "        valid_cats = counts[counts >= 2].index\n",
    "        sub = sub[sub[\"category\"].isin(valid_cats)]\n",
    "        if sub[\"category\"].nunique() < 2:\n",
    "            continue\n",
    "\n",
    "    # ————— ANOVA —————\n",
    "    model = ols(\"covid_full_ratio ~ C(category)\", data=sub).fit()\n",
    "    anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "    anova_p = float(anova_table[\"PR(>F)\"].iloc[0])\n",
    "    cat_results.append({\n",
    "        \"metric\": m,\n",
    "        \"n_elites\": len(sub),\n",
    "        \"n_categories\": sub[\"category\"].nunique(),\n",
    "        \"anova_p\": anova_p,\n",
    "        \"anova_sig\": \"Yes\" if anova_p < 0.05 else \"No\"\n",
    "    })\n",
    "\n",
    "    # ————— Tukey HSD (only if ANOVA suggests differences) —————\n",
    "    if anova_p < 0.10:  # you can relax to 0.10 or keep 0.05\n",
    "        try:\n",
    "            tukey = pairwise_tukeyhsd(\n",
    "                endog=sub[\"covid_full_ratio\"],\n",
    "                groups=sub[\"category\"],\n",
    "                alpha=0.05\n",
    "            )\n",
    "            tukey_path = tukey_dir / f\"Tukey_{m.replace('/', '_')}.txt\"\n",
    "            with open(tukey_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(tukey.summary().as_text())\n",
    "            print(f\"   → Tukey saved for {m}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   → Tukey failed for {m}: {e}\")\n",
    "    else:\n",
    "        print(f\"   → {m}: ANOVA not suggestive (p={anova_p:.3f}), skipping Tukey\")\n",
    "\n",
    "# Save summary table\n",
    "results_df = pd.DataFrame(cat_results)\n",
    "results_df = results_df.sort_values(\"anova_p\")\n",
    "results_df.to_csv(STEP5_DIR / \"category_anova_results.csv\", index=False)\n",
    "\n",
    "print(\"\\nBlock 6 finished!\")\n",
    "print(f\"   ANOVA results saved → {len(results_df)} metrics tested\")\n",
    "print(f\"   Significant at p<0.05 → {results_df['anova_p'].lt(0.05).sum()}\")\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc1c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 7 — Mediation analysis\n",
    "# ==============================\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "\n",
    "# pick the metric: avg_closeness\n",
    "sub = merged[merged[\"metric\"]==\"avg_closeness\"].copy()\n",
    "sub = sub[sub[\"p_two_sided\"]<0.05].copy()\n",
    "sub = sub.dropna(subset=[\"covid_full_ratio\",\"followers\",\"full_density\"])\n",
    "\n",
    "sub[\"log_followers\"] = np.log1p(sub[\"followers\"])\n",
    "\n",
    "# mediator model M ~ X\n",
    "mediator_model = smf.ols(\"full_density ~ log_followers + age + C(category)\", data=sub)\n",
    "\n",
    "# outcome model Y ~ X + M\n",
    "outcome_model = smf.ols(\"covid_full_ratio ~ log_followers + full_density + age + C(category)\", data=sub)\n",
    "\n",
    "med = Mediation(outcome_model, mediator_model, \"log_followers\", \"full_density\").fit()\n",
    "\n",
    "with open(STEP5_DIR/\"mediation_followers_density_closeness.txt\",\"w\") as f:\n",
    "    f.write(str(med.summary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BLOCK 8 — Master Excel output\n",
    "# ==============================\n",
    "writer = pd.ExcelWriter(STEP5_DIR/\"MASTER_REPORT.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "combined_long.to_excel(writer, sheet_name=\"combined_long\", index=False)\n",
    "merged.to_excel(writer, sheet_name=\"merged\", index=False)\n",
    "summary_df.to_excel(writer, sheet_name=\"coverage_summary\", index=False)\n",
    "pd.DataFrame(reg_results).to_excel(writer, sheet_name=\"regression_overview\", index=False)\n",
    "pd.DataFrame(cat_results).to_excel(writer, sheet_name=\"category_ANOVA\", index=False)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(\"MASTER_REPORT.xlsx created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# BLOCK 9 — Corrected Category-Difference Plot + Full Significance Heatmap\n",
    "# ================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PLOT_DIR = STEP5_DIR / \"visualizations\"\n",
    "PLOT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper: signed-log transform\n",
    "# ------------------------------------------------------------\n",
    "def signed_log(x, eps=1e-9):\n",
    "    x = np.asarray(x, float)\n",
    "    return np.sign(x) * np.log10(np.abs(x) + eps)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# A. CATEGORY-DIFFERENCE FIGURE (all 9 metrics, fixed widths + dashed grid)\n",
    "# ------------------------------------------------------------\n",
    "anova_res = pd.read_csv(STEP5_DIR/\"category_anova_results.csv\")\n",
    "all_metrics = anova_res[\"metric\"].tolist()   # use ALL 9 metrics\n",
    "\n",
    "plot_df = merged[merged[\"metric\"].isin(all_metrics)].copy()\n",
    "plot_df[\"signedlog_ratio\"] = signed_log(plot_df[\"covid_full_ratio\"])\n",
    "\n",
    "categories = [\n",
    "    \"Politicians and World Leaders\",\n",
    "    \"Entertainers and Celebrities\",\n",
    "    \"Business Leaders and Entrepreneurs\",\n",
    "]\n",
    "palette = sns.color_palette(\"Set2\", 3)\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Draw violinplot\n",
    "sns.violinplot(\n",
    "    data=plot_df,\n",
    "    x=\"metric\",\n",
    "    y=\"signedlog_ratio\",\n",
    "    hue=\"category\",\n",
    "    split=False,\n",
    "    inner=None,\n",
    "    palette=palette,\n",
    "    cut=0\n",
    ")\n",
    "\n",
    "# Draw *narrower* grouped boxplots manually\n",
    "x_positions = np.arange(len(all_metrics))\n",
    "offsets = [-0.25, 0, 0.25]\n",
    "box_width = 0.05\n",
    "\n",
    "for i, cat in enumerate(categories):\n",
    "    subset = plot_df[plot_df[\"category\"] == cat]\n",
    "    sns.boxplot(\n",
    "        data=subset,\n",
    "        x=\"metric\",\n",
    "        y=\"signedlog_ratio\",\n",
    "        positions=x_positions + offsets[i],\n",
    "        width=box_width,\n",
    "        showcaps=True,\n",
    "        boxprops={\"facecolor\": \"white\", \"zorder\": 3},\n",
    "        showfliers=False,\n",
    "        whiskerprops={\"linewidth\": 1},\n",
    "        medianprops={\"color\": \"black\", \"linewidth\": 1.5}\n",
    "    )\n",
    "\n",
    "# ----------------------\n",
    "# ★ Add light dashed grid\n",
    "# ----------------------\n",
    "plt.grid(\n",
    "    axis='y',\n",
    "    linestyle='--',\n",
    "    linewidth=0.6,\n",
    "    alpha=0.35\n",
    ")\n",
    "\n",
    "plt.title(\"Category Differences in COVID-Era Discourse Restructuring\", fontsize=17)\n",
    "plt.xlabel(\"Metric\", fontsize=14)\n",
    "plt.ylabel(\"Signed log₁₀(COVID/Full Ratio)\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend(title=\"Category\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR/\"Fig_Category_Differences_FIXED2.png\", dpi=450)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# B. FULL REGRESSION SIGNIFICANCE HEATMAP (all predictors included)\n",
    "# =============================================================\n",
    "reg_overview = pd.read_csv(STEP5_DIR/\"regression_overview.csv\")\n",
    "\n",
    "# All dependent variables (all 9)\n",
    "dependent_vars = [\n",
    "    \"avg_closeness\",\"avg_degree\",\"avg_pagerank\",\"centralization_top3\",\n",
    "    \"clustering\",\"density\",\"modularity\",\"n_edges\",\"n_nodes\"\n",
    "]\n",
    "\n",
    "# All independent predictors you listed\n",
    "predictors = [\n",
    "    \"log_followers\",\"age\",\"years_active\",\n",
    "    \"full_density\",\"full_clustering\",\"full_modularity\",\n",
    "    \"full_centralization_top3\",\"full_n_nodes\",\"full_n_edges\",\n",
    "    \"full_avg_degree\",\"full_avg_closeness\",\"full_avg_pagerank\"\n",
    "]\n",
    "\n",
    "heat_rows = []\n",
    "\n",
    "for dep in dependent_vars:\n",
    "    summary_file = REG_DIR / f\"{dep}_reg_summary.txt\"\n",
    "    if not summary_file.exists():\n",
    "        continue\n",
    "    with open(summary_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    collect = False\n",
    "    for line in lines:\n",
    "        if \"coef\" in line and \"std err\" in line:\n",
    "            collect = True\n",
    "            continue\n",
    "        if collect:\n",
    "            if line.strip() == \"\":\n",
    "                break\n",
    "            parts = line.split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "\n",
    "            var = parts[0]\n",
    "            if var not in predictors:\n",
    "                continue\n",
    "\n",
    "            pval = float(parts[-1])\n",
    "            if pval < 0.001:\n",
    "                sig = 3\n",
    "            elif pval < 0.01:\n",
    "                sig = 2\n",
    "            elif pval < 0.05:\n",
    "                sig = 1\n",
    "            else:\n",
    "                sig = 0\n",
    "\n",
    "            heat_rows.append([dep, var, sig])\n",
    "\n",
    "heat_df = pd.DataFrame(heat_rows, columns=[\"dependent\", \"predictor\", \"sig\"])\n",
    "heat_map = heat_df.pivot(index=\"dependent\", columns=\"predictor\", values=\"sig\").fillna(0)\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(\n",
    "    heat_map,\n",
    "    cmap=\"YlGnBu\",\n",
    "    linewidths=0.6,\n",
    "    linecolor=\"white\",\n",
    "    annot=True,\n",
    "    fmt=\".0f\",\n",
    "    cbar_kws={\n",
    "        \"label\": \"Significance Level\\n(3: p < 0.001, 2: p < 0.01, 1: p < 0.05, 0: ns ≥ 0.05)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.title(\"Regression Significance Across Predictors\", fontsize=18)\n",
    "plt.xlabel(\"Independent Predictor\", fontsize=14)\n",
    "plt.ylabel(\"Dependent Variable\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR/\"Fig_Regression_Significance_Heatmap_FULL.png\", dpi=450)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Updated figures saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
